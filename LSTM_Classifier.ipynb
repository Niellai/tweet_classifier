{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import import_notebook\n",
    "from readWrite import ReadWrite\n",
    "from vectorToDoc import VectorToDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 1125\n",
      "Read complete, total records: 1125\n",
      "x_train: 901, shape: (901, 20)\n",
      "y_train: 901, shape: (901,)\n",
      "x_test: 224, shape: (224, 20)\n",
      "y_test: 224, shape: (224,)\n",
      "encoding_train shape: (901, 3)\n",
      "encoding_test shape: (224, 3)\n"
     ]
    }
   ],
   "source": [
    "tweetFile = \"combineVectors.csv\"\n",
    "tweetClassFile = \"combineVectorsResult.txt\"\n",
    "\n",
    "readWrite = ReadWrite()\n",
    "xdata = readWrite.readFile(tweetFile)\n",
    "ydata = readWrite.readFileClassifier(tweetClassFile)\n",
    "\n",
    "x_train = xdata[:int(len(xdata) * 0.8) + 1]\n",
    "y_train = ydata[:int(len(ydata) * 0.8) + 1]\n",
    "x_test = xdata[int(len(xdata) * 0.8):-1]\n",
    "y_test = ydata[int(len(ydata) * 0.8):-1]\n",
    "\n",
    "print(\"x_train: {}, shape: {}\".format(len(x_train), x_train.shape))\n",
    "print(\"y_train: {}, shape: {}\".format(len(y_train), y_train.shape))\n",
    "print(\"x_test: {}, shape: {}\".format(len(x_test), x_test.shape))\n",
    "print(\"y_test: {}, shape: {}\".format(len(y_test), y_test.shape))\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ydata)\n",
    "encoded = encoder.transform(ydata)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "encoding = np_utils.to_categorical(encoded)\n",
    "\n",
    "encoding_train = encoding[:int(len(xdata) * 0.8) + 1]\n",
    "encoding_test = encoding[int(len(ydata) * 0.8):-1]\n",
    "print(\"encoding_train shape: {}\".format(encoding_train.shape))\n",
    "print(\"encoding_test shape: {}\".format(encoding_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 64)            128000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 194,303\n",
      "Trainable params: 194,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabSize = 2000\n",
    "outputDim = 64\n",
    "recordsSize = 20\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, outputDim, input_length=recordsSize))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, input_dim=(20,), activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 901 samples, validate on 224 samples\n",
      "Epoch 1/35\n",
      "901/901 [==============================] - 0s - loss: 0.0156 - acc: 0.9937 - val_loss: 0.6305 - val_acc: 0.8780\n",
      "Epoch 2/35\n",
      "901/901 [==============================] - 0s - loss: 0.0152 - acc: 0.9941 - val_loss: 0.6446 - val_acc: 0.8690\n",
      "Epoch 3/35\n",
      "901/901 [==============================] - 0s - loss: 0.0138 - acc: 0.9952 - val_loss: 0.7188 - val_acc: 0.8705\n",
      "Epoch 4/35\n",
      "901/901 [==============================] - 0s - loss: 0.0142 - acc: 0.9948 - val_loss: 0.8740 - val_acc: 0.8452\n",
      "Epoch 5/35\n",
      "901/901 [==============================] - 0s - loss: 0.0199 - acc: 0.9908 - val_loss: 0.5505 - val_acc: 0.8780\n",
      "Epoch 6/35\n",
      "901/901 [==============================] - 0s - loss: 0.0229 - acc: 0.9900 - val_loss: 0.8178 - val_acc: 0.8557\n",
      "Epoch 7/35\n",
      "901/901 [==============================] - 0s - loss: 0.0213 - acc: 0.9930 - val_loss: 0.6351 - val_acc: 0.8690\n",
      "Epoch 8/35\n",
      "901/901 [==============================] - 0s - loss: 0.0221 - acc: 0.9911 - val_loss: 0.6497 - val_acc: 0.8795\n",
      "Epoch 9/35\n",
      "901/901 [==============================] - 0s - loss: 0.0129 - acc: 0.9930 - val_loss: 0.7038 - val_acc: 0.8720\n",
      "Epoch 10/35\n",
      "901/901 [==============================] - 0s - loss: 0.0169 - acc: 0.9956 - val_loss: 0.7226 - val_acc: 0.8631\n",
      "Epoch 11/35\n",
      "901/901 [==============================] - 0s - loss: 0.0095 - acc: 0.9963 - val_loss: 0.8908 - val_acc: 0.8586\n",
      "Epoch 12/35\n",
      "901/901 [==============================] - 0s - loss: 0.0201 - acc: 0.9941 - val_loss: 0.4726 - val_acc: 0.8839\n",
      "Epoch 13/35\n",
      "901/901 [==============================] - 0s - loss: 0.0181 - acc: 0.9926 - val_loss: 0.7700 - val_acc: 0.8735\n",
      "Epoch 14/35\n",
      "901/901 [==============================] - 0s - loss: 0.0173 - acc: 0.9937 - val_loss: 0.7736 - val_acc: 0.8795\n",
      "Epoch 15/35\n",
      "901/901 [==============================] - 0s - loss: 0.0161 - acc: 0.9926 - val_loss: 0.4376 - val_acc: 0.8988\n",
      "Epoch 16/35\n",
      "901/901 [==============================] - 0s - loss: 0.0178 - acc: 0.9937 - val_loss: 0.7586 - val_acc: 0.8780\n",
      "Epoch 17/35\n",
      "901/901 [==============================] - 0s - loss: 0.0120 - acc: 0.9952 - val_loss: 0.7603 - val_acc: 0.8795\n",
      "Epoch 18/35\n",
      "901/901 [==============================] - 0s - loss: 0.0108 - acc: 0.9959 - val_loss: 0.6115 - val_acc: 0.8899\n",
      "Epoch 19/35\n",
      "901/901 [==============================] - 0s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.7060 - val_acc: 0.8854\n",
      "Epoch 20/35\n",
      "901/901 [==============================] - 0s - loss: 0.0126 - acc: 0.9959 - val_loss: 0.7674 - val_acc: 0.8676\n",
      "Epoch 21/35\n",
      "901/901 [==============================] - 0s - loss: 0.0080 - acc: 0.9967 - val_loss: 0.6809 - val_acc: 0.8780\n",
      "Epoch 22/35\n",
      "901/901 [==============================] - 0s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.8626 - val_acc: 0.8586\n",
      "Epoch 23/35\n",
      "901/901 [==============================] - 0s - loss: 0.0044 - acc: 0.9982 - val_loss: 0.8972 - val_acc: 0.8661\n",
      "Epoch 24/35\n",
      "901/901 [==============================] - 0s - loss: 0.0119 - acc: 0.9956 - val_loss: 0.8371 - val_acc: 0.8750\n",
      "Epoch 25/35\n",
      "901/901 [==============================] - 0s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.7187 - val_acc: 0.8795\n",
      "Epoch 26/35\n",
      "901/901 [==============================] - 0s - loss: 0.0127 - acc: 0.9963 - val_loss: 0.6001 - val_acc: 0.8884\n",
      "Epoch 27/35\n",
      "901/901 [==============================] - 0s - loss: 0.0133 - acc: 0.9945 - val_loss: 0.5148 - val_acc: 0.8914\n",
      "Epoch 28/35\n",
      "901/901 [==============================] - 0s - loss: 0.0178 - acc: 0.9956 - val_loss: 0.5805 - val_acc: 0.8958\n",
      "Epoch 29/35\n",
      "901/901 [==============================] - 0s - loss: 0.0097 - acc: 0.9956 - val_loss: 0.9379 - val_acc: 0.8542\n",
      "Epoch 30/35\n",
      "901/901 [==============================] - 0s - loss: 0.0089 - acc: 0.9959 - val_loss: 1.1112 - val_acc: 0.8438\n",
      "Epoch 31/35\n",
      "901/901 [==============================] - 0s - loss: 0.0062 - acc: 0.9982 - val_loss: 1.1762 - val_acc: 0.8423\n",
      "Epoch 32/35\n",
      "901/901 [==============================] - 0s - loss: 0.0155 - acc: 0.9945 - val_loss: 0.4218 - val_acc: 0.9107\n",
      "Epoch 33/35\n",
      "901/901 [==============================] - 0s - loss: 0.0224 - acc: 0.9926 - val_loss: 0.6000 - val_acc: 0.9048\n",
      "Epoch 34/35\n",
      "901/901 [==============================] - 0s - loss: 0.0126 - acc: 0.9963 - val_loss: 0.5976 - val_acc: 0.8869\n",
      "Epoch 35/35\n",
      "901/901 [==============================] - 0s - loss: 0.0136 - acc: 0.9948 - val_loss: 0.5373 - val_acc: 0.9033\n",
      "Accuracy: 90.33%\n"
     ]
    }
   ],
   "source": [
    "batch_size = outputDim\n",
    "epochs = 35\n",
    "\n",
    "model.fit(x_train, encoding_train, validation_data=(x_test, encoding_test), epochs=epochs, batch_size=outputDim)\n",
    "scores = model.evaluate(x_test, encoding_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 510\n",
      "320/510 [=================>............] - ETA: 0s\n",
      "(510,)\n",
      "2\n",
      "@SMRT_Singapore @ChannelNewsAsia EVERY WEEK SAME ðŸ’©just different days When r we goin to have one fcuking wk w/o anyâ€¦ https://t.co/7Fn26Oc5G0\n",
      "\n",
      "1\n",
      "@SBSTransit_Ltd is it too much to ask that your drivers be trained in driving? Nausea should not be a normal part of a short bus ride! ðŸ¤¢\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Just board train towards bukit batok from jurong east. Running normal.\n",
      "\n",
      "1\n",
      "@SMRT_Singapore please ACTIVATE YOUR SHUTTLE BUS STOP SAVING FKING MONEY\n",
      "\n",
      "2\n",
      "@SMRT_Singapore daily delays in red line ðŸ˜‘\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Shit. Raining day. Sure delay at NSL with any kind of reasons.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore red line red line!!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore The red line towards Marina Bay is stuck between bradell andToa payoh for past 15mins.This is very frustrating\n",
      "\n",
      "1\n",
      "@SMRT_Singapore @ChannelNewsAsia Again&gt;&lt;\n",
      "\n",
      "1\n",
      "@SMRT_Singapore Air con down as well in this current train. 3232\n",
      "\n",
      "2\n",
      "[Bus service]Bus services affected by road closures in Chinatown on 1 October, 4pm to 11.59pm. https://t.co/vh91O9CoAR\n",
      "\n",
      "2\n",
      "@SMRT_Singapore The trains on EW line has been running slower these past few days\n",
      "\n",
      "2\n",
      "@SMRT_Singapore delay everyday.train delay every single day. takes the same time from outram park to clementi and clementi to pioneer.\n",
      "\n",
      "1\n",
      "@SMRT_Singapore Hi am on the red line now towards Marina Bay what's with all the stopping and starting? A 1hr journey for me is now 1.5hr :(\n",
      "\n",
      "1\n",
      "@SBSTransit_Ltd It has been longer than 10 minute. I think it is more responsible for SMRT to revise train delay time\n",
      "\n",
      "2\n",
      "The Power Rail Replacement Project is now complete!âœ”Take a look at the effort and planning that led up to this momentâ€¦ https://t.co/CFIkoSSYyf\n",
      "\n",
      "1\n",
      "@SMRT_Singapore Eh, hello? Green line also problematic since 7am! Can be more responsible and report truthfully or not? Tsk!\n",
      "\n",
      "1\n",
      "@SMRT_Singapore Why no free shuttle bus at Pasir Panjang station ? Where by all stations are delay in departure ?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore we are on Harbourfront bound circle line, stuck at LorongChua, no announcement inside othr thn 5mim delay. Now 10min\n",
      "\n",
      "1\n",
      "@SMRT_Singapore specify which line, a couple of lines connect the 2 stations. Your train service may not be up to par -â€¦ https://t.co/HRZhGFaGMg\n",
      "\n",
      "1\n",
      "[BPLRT] CLEARED: Free bus and bridging bus services have ended. We apologise for the inconvenience caused.\n",
      "\n",
      "1\n",
      "@SMRT_Singapore i unprivated my acv just to tell u. U dont have to delay the train ( NSL ) Every fucking time in the day.\n",
      "\n",
      "2\n",
      "[Bus service]Operating hrs of DTL, NEL and Sengkang/Punggol LRT and bus services 181, 222, 225G and 243G will be extended during F1 race days, 15 - 17 Sep.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorsArr2 = readWrite.readFile('docVectors3.csv')\n",
    "oriRecords2 = readWrite.readOriFile('user_tweets3.txt')\n",
    "\n",
    "classResult = []\n",
    "predicted = model.predict_classes(vectorsArr2)\n",
    "predicted = np.reshape(predicted, (predicted.size,))\n",
    "\n",
    "print()\n",
    "print(predicted.shape)\n",
    "\n",
    "for idx, score in enumerate(predicted):    \n",
    "    if(score >= 1): \n",
    "        classResult.append(oriRecords2[idx])       \n",
    "        print(predicted[idx])\n",
    "        print(oriRecords2[idx])        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
