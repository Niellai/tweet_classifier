{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\himur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\himur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    fileName = \"user_tweets.txt\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    porterStem = PorterStemmer()                \n",
    "    dictMap = {}\n",
    "    \n",
    "    # alphanumeric\n",
    "    def getNumericWords(self, text):\n",
    "        return re.compile('\\w+').findall(text)\n",
    "\n",
    "    # alphabets only\n",
    "    def getWords(self, text):\n",
    "        # ref: https://stackoverflow.com/questions/7633274/extracting-words-from-a-string-removing-punctuation-and-returning-a-list-with-s\n",
    "        # c.isalnum -> alphaNumeric    \n",
    "        return ''.join((c if c.isalpha() else ' ') for c in text).split()\n",
    "\n",
    "    # remove url from tweet\n",
    "    def removeUrl(self, text):\n",
    "        formText = ''\n",
    "        textArr = text.split()\n",
    "        for text in textArr:\n",
    "            if text.find(\"http\") < 0:\n",
    "                formText += ' ' + text \n",
    "        return formText\n",
    "\n",
    "    '''\n",
    "    Reading pure dataset only contain record of tweet per line.\n",
    "    - Stop words will be filtered in tweet\n",
    "    - If dataset is small consider stemming, reduce dictionary size\n",
    "    - Returns array of words, each record is an array\n",
    "    '''\n",
    "    def readFile(self, fileName, isStemming=False):\n",
    "        resultArr = []\n",
    "        with codecs.open(fileName, \"r\", encoding=\"utf-8\", errors='ignore') as file:                 \n",
    "            for line in file.readlines():     \n",
    "                line = line.lower()\n",
    "                line = self.removeUrl(line)            \n",
    "                lineArr = self.getWords(line)            \n",
    "                filtered_lineArr = [word for word in lineArr if not word in self.stop_words]                        \n",
    "\n",
    "                if isStemming:\n",
    "                    stem_lineArr = []\n",
    "                    for word in filtered_lineArr:\n",
    "                        stem_lineArr.append(self.porterStem.stem(word))                \n",
    "                    resultArr.append(stem_lineArr)\n",
    "                else:                                \n",
    "                    resultArr.append(filtered_lineArr)            \n",
    "            return resultArr\n",
    "    \n",
    "    def readSentence(self, sentence, isStemming=False):\n",
    "        resultArr = []\n",
    "        line = sentence.lower()\n",
    "        line = self.removeUrl(line)            \n",
    "        lineArr = self.getWords(line)            \n",
    "        filtered_lineArr = [word for word in lineArr if not word in self.stop_words]                        \n",
    "\n",
    "        if isStemming:\n",
    "            stem_lineArr = []\n",
    "            for word in filtered_lineArr:\n",
    "                stem_lineArr.append(self.porterStem.stem(word))                \n",
    "            resultArr.append(stem_lineArr)\n",
    "        else:                                \n",
    "            resultArr.append(filtered_lineArr)            \n",
    "        return resultArr\n",
    "    \n",
    "    '''\n",
    "    Create dictionary set on words array\n",
    "    '''\n",
    "    def createSet(self, tweetWordsArr):\n",
    "        result = set()\n",
    "        for words in tweetWordsArr:\n",
    "            wordsSet = set(words)\n",
    "            for word in wordsSet:\n",
    "                result.add(word)        \n",
    "        return result\n",
    "    \n",
    "    # input wordset only, create sets from createSet()\n",
    "    # all words have to be in lower caps, except of these 2 key words:\n",
    "    # NONE - first item, UNK - last time\n",
    "    def createVector(self, tweetWordsSet):\n",
    "        if len(self.dictMap) == 0:\n",
    "            tweetWordsSet = list(tweetWordsSet)\n",
    "            tweetWordsSet.insert(0, \"NONE\")\n",
    "            tweetWordsSet.insert(len(tweetWordsSet), \"UNK\")        \n",
    "            for idx, word in enumerate(tweetWordsSet):\n",
    "                self.dictMap[word] = idx        \n",
    "        return self.dictMap\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pleas', 'inform', 'train', 'woodland', 'amk']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fileName = \"user_tweets.txt\"\n",
    "# dic = Dictionary()\n",
    "# resultArr = dic.readFile(fileName, True)\n",
    "# resultSets = dic.createSet(resultArr)\n",
    "# dicMap = dic.createVector(resultSets)\n",
    "\n",
    "# print(\"Dictionary count: {}\".format(len(resultSets)))\n",
    "# print(dicMap)\n",
    "\n",
    "# dic.readSentence(\"Please be informed that there will be no train between woodlands and amk\", True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
