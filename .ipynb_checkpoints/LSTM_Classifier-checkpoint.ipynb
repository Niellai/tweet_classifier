{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from readWrite.ipynb\n",
      "importing Jupyter notebook from vectorToDoc.ipynb\n",
      "importing Jupyter notebook from dictionary.ipynb\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NielPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NielPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import import_notebook\n",
    "from readWrite import ReadWrite\n",
    "from vectorToDoc import VectorToDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 1125\n",
      "Read complete, total records: 1125\n",
      "x_train: 901, shape: (901, 20)\n",
      "y_train: 901, shape: (901,)\n",
      "x_test: 224, shape: (224, 20)\n",
      "y_test: 224, shape: (224,)\n",
      "encoding_train shape: (901, 3)\n",
      "encoding_test shape: (224, 3)\n"
     ]
    }
   ],
   "source": [
    "tweetFile = \"combineVectors.csv\"\n",
    "tweetClassFile = \"combineVectorsResult.txt\"\n",
    "\n",
    "readWrite = ReadWrite()\n",
    "xdata = readWrite.readFile(tweetFile)\n",
    "ydata = readWrite.readFileClassifier(tweetClassFile)\n",
    "\n",
    "x_train = xdata[:int(len(xdata) * 0.8) + 1]\n",
    "y_train = ydata[:int(len(ydata) * 0.8) + 1]\n",
    "x_test = xdata[int(len(xdata) * 0.8):-1]\n",
    "y_test = ydata[int(len(ydata) * 0.8):-1]\n",
    "\n",
    "print(\"x_train: {}, shape: {}\".format(len(x_train), x_train.shape))\n",
    "print(\"y_train: {}, shape: {}\".format(len(y_train), y_train.shape))\n",
    "print(\"x_test: {}, shape: {}\".format(len(x_test), x_test.shape))\n",
    "print(\"y_test: {}, shape: {}\".format(len(y_test), y_test.shape))\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ydata)\n",
    "encoded = encoder.transform(ydata)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "encoding = np_utils.to_categorical(encoded)\n",
    "\n",
    "encoding_train = encoding[:int(len(xdata) * 0.8) + 1]\n",
    "encoding_test = encoding[int(len(ydata) * 0.8):-1]\n",
    "print(\"encoding_train shape: {}\".format(encoding_train.shape))\n",
    "print(\"encoding_test shape: {}\".format(encoding_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabSize = 2000\n",
    "outputDim = 64\n",
    "recordsSize = 20\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, outputDim, input_length=recordsSize))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, input_dim=(20,), activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 901 samples, validate on 224 samples\n",
      "Epoch 1/30\n",
      "901/901 [==============================] - 2s - loss: 0.5305 - acc: 0.7333 - val_loss: 0.2057 - val_acc: 0.9375\n",
      "Epoch 2/30\n",
      "901/901 [==============================] - 0s - loss: 0.4083 - acc: 0.8524 - val_loss: 0.2588 - val_acc: 0.9375\n",
      "Epoch 3/30\n",
      "901/901 [==============================] - 0s - loss: 0.3683 - acc: 0.8561 - val_loss: 0.2317 - val_acc: 0.9405\n",
      "Epoch 4/30\n",
      "901/901 [==============================] - 0s - loss: 0.3085 - acc: 0.8724 - val_loss: 0.1889 - val_acc: 0.9375\n",
      "Epoch 5/30\n",
      "901/901 [==============================] - 0s - loss: 0.2337 - acc: 0.9038 - val_loss: 0.1708 - val_acc: 0.9449\n",
      "Epoch 6/30\n",
      "901/901 [==============================] - 0s - loss: 0.1933 - acc: 0.9057 - val_loss: 0.1942 - val_acc: 0.9315\n",
      "Epoch 7/30\n",
      "901/901 [==============================] - 0s - loss: 0.1636 - acc: 0.9046 - val_loss: 0.2208 - val_acc: 0.9167\n",
      "Epoch 8/30\n",
      "901/901 [==============================] - 0s - loss: 0.1436 - acc: 0.9190 - val_loss: 0.2365 - val_acc: 0.9241\n",
      "Epoch 9/30\n",
      "901/901 [==============================] - 0s - loss: 0.1426 - acc: 0.9171 - val_loss: 0.2848 - val_acc: 0.9048\n",
      "Epoch 10/30\n",
      "901/901 [==============================] - 0s - loss: 0.1327 - acc: 0.9216 - val_loss: 0.2370 - val_acc: 0.9167\n",
      "Epoch 11/30\n",
      "901/901 [==============================] - 0s - loss: 0.1235 - acc: 0.9301 - val_loss: 0.2512 - val_acc: 0.9167\n",
      "Epoch 12/30\n",
      "901/901 [==============================] - 0s - loss: 0.1209 - acc: 0.9408 - val_loss: 0.2432 - val_acc: 0.8958\n",
      "Epoch 13/30\n",
      "901/901 [==============================] - 0s - loss: 0.1340 - acc: 0.9371 - val_loss: 0.2337 - val_acc: 0.9003\n",
      "Epoch 14/30\n",
      "901/901 [==============================] - 0s - loss: 0.1112 - acc: 0.9471 - val_loss: 0.2894 - val_acc: 0.8884\n",
      "Epoch 15/30\n",
      "901/901 [==============================] - 0s - loss: 0.1054 - acc: 0.9515 - val_loss: 0.3441 - val_acc: 0.8884\n",
      "Epoch 16/30\n",
      "901/901 [==============================] - 0s - loss: 0.0953 - acc: 0.9667 - val_loss: 0.3388 - val_acc: 0.8869\n",
      "Epoch 17/30\n",
      "901/901 [==============================] - 0s - loss: 0.1175 - acc: 0.9452 - val_loss: 0.3182 - val_acc: 0.8780\n",
      "Epoch 18/30\n",
      "901/901 [==============================] - 0s - loss: 0.0956 - acc: 0.9649 - val_loss: 0.3171 - val_acc: 0.8720\n",
      "Epoch 19/30\n",
      "901/901 [==============================] - 0s - loss: 0.0938 - acc: 0.9667 - val_loss: 0.3474 - val_acc: 0.8616\n",
      "Epoch 20/30\n",
      "901/901 [==============================] - 0s - loss: 0.0888 - acc: 0.9674 - val_loss: 0.3279 - val_acc: 0.8824\n",
      "Epoch 21/30\n",
      "901/901 [==============================] - 0s - loss: 0.0673 - acc: 0.9763 - val_loss: 0.4151 - val_acc: 0.8557\n",
      "Epoch 22/30\n",
      "901/901 [==============================] - 0s - loss: 0.0616 - acc: 0.9804 - val_loss: 0.3886 - val_acc: 0.8795\n",
      "Epoch 23/30\n",
      "901/901 [==============================] - 0s - loss: 0.0588 - acc: 0.9826 - val_loss: 0.4235 - val_acc: 0.8661\n",
      "Epoch 24/30\n",
      "901/901 [==============================] - 0s - loss: 0.0594 - acc: 0.9834 - val_loss: 0.3821 - val_acc: 0.8765\n",
      "Epoch 25/30\n",
      "901/901 [==============================] - 0s - loss: 0.0540 - acc: 0.9856 - val_loss: 0.4024 - val_acc: 0.8690\n",
      "Epoch 26/30\n",
      "901/901 [==============================] - 0s - loss: 0.0584 - acc: 0.9819 - val_loss: 0.3929 - val_acc: 0.8795\n",
      "Epoch 27/30\n",
      "901/901 [==============================] - 0s - loss: 0.0447 - acc: 0.9859 - val_loss: 0.4706 - val_acc: 0.8616\n",
      "Epoch 28/30\n",
      "901/901 [==============================] - 0s - loss: 0.0409 - acc: 0.9878 - val_loss: 0.5351 - val_acc: 0.8452\n",
      "Epoch 29/30\n",
      "901/901 [==============================] - 0s - loss: 0.0478 - acc: 0.9848 - val_loss: 0.4968 - val_acc: 0.8363\n",
      "Epoch 30/30\n",
      "901/901 [==============================] - 0s - loss: 0.0483 - acc: 0.9871 - val_loss: 0.3684 - val_acc: 0.8810\n",
      "Accuracy: 88.10%\n"
     ]
    }
   ],
   "source": [
    "batch_size = outputDim\n",
    "epochs = 30\n",
    "\n",
    "model.fit(x_train, encoding_train, validation_data=(x_test, encoding_test), epochs=epochs, batch_size=outputDim)\n",
    "scores = model.evaluate(x_test, encoding_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 370\n",
      "320/370 [========================>.....] - ETA: 0s\n",
      "[0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 0 2 0 0 0 2 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 2 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 1 1 1 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 1 2 0 0 0 0 2 1 0 0 0 0 2 0 2 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 2 0 0 0 1 0 2\n",
      " 0 0 0 1 0 2 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2]\n",
      "2\n",
      "@SMRT_Singapore is there a track fault?? Why is your train stuck at Tanah Merah towards Pasir Ris\n",
      "\n",
      "2\n",
      "@SMRT_Singapore EWL, West bound, train is stopping more than a minute since Bedok. Is there anything that would like to announce?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore What's up with the slow moving trains on EW line this morning?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore still no train fault announcement?! How do u expect commuters to plan their journey?! https://t.co/Vx6cyzMCbA\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Are u sure there's no train fault now?? How come no announcement? Been at the platform for 30mins yet can't board the train!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore amk nsl is so crowded.. yet platform traffic is green..r u kidding me?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore, for sure there is a fault somewhere along EWL. West bound, the train is stopping each stop for longer time. Damn!!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore why does the train stop at pioneer station for more than 5 minutes every morning before it moves off?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Your train stopped 8 minutes in the middle of track towards Boon Lay. Now it has already stopped 5 minuteâ€¦ https://t.co/V66Qz9R5ef\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Again, this train stopped 5 minutes in the middle of track towards Pioneer when it has stopped 8 minutes earlier at Boon Lay.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore delayed from Lakeside to Joo Koon.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore always slow as usual. Train stops at stations are way too long.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Hi am on the red line now towards Marina Bay what's with all the stopping and starting? A 1hr journey for me is now 1.5hr :(\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Stop n tuas west n u turn back but u nvr announce, yr train is already so slow n still no announce, what the\n",
      "\n",
      "2\n",
      "@SMRT_Singapore @LTAsg Lucky still got my car. Can imagine if I heed the papaya advise without my car? Then I be kau beh kau buh  oso.\n",
      "\n",
      "1\n",
      "[NSL] CLEARED: Train services between #MarinaSouthPier and #ToaPayoh have resumed. Free regular bus services have ended.\n",
      "\n",
      "1\n",
      "[NSL] UPDATE: Free regular bus services between #MarinaSouthPier and #ToaPayoh is still available.\n",
      "\n",
      "1\n",
      "[NSL]UPDATE: Fault Cleared.Train services are progressively being restored.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore No train service at Toa Payoh to Marina South Pier in both directions\n",
      "\n",
      "2\n",
      "@SMRT_Singapore FIX IT. IF YOU CAN'T GET SOMEONE ELSE TO DO IT!!! #rubbishmrt #useless @LTAsg  can u do something???????\n",
      "\n",
      "2\n",
      "[NSL] UPDATE: Free regular bus services between #MarinaSouthPier and #ToaPayoh.\n",
      "\n",
      "2\n",
      "[NSL]: Due to a signalling fault on the new signalling system, please add 20mins train travel time between #MarinaSouthPier and #ToaPayoh.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Train delay on nsl, start stop along the way to jurong east. Worse still, stuffy train which make it feel like vomitting.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore hi all, train delay on ns line towards jurong east, by start-stop along the way. Train carriage was stuffy too.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Damn it, 1 hr 31mins from Pasir Ris to Joo Koon. No announcement at all!!!!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore, WTH is going on? Pasir Ris to Boon Lay 1hr 23mins!!!!! I am travelling Pasir Ris to Joon Koon EVERYDAY! LATE AGAIN!!!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Train stopped at Dhoby Ghaut for 20 minutes without any announcement! Refused to admit your mistake or you gave up?\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Train fault at Pioneer #lta_sg\n",
      "\n",
      "2\n",
      "@SMRT_Singapore, what is wrong with EWL? Why the train is travelling at 40km/hr? Joo Koon to Chinese Garden\n",
      "\n",
      "1\n",
      "[Bus service]Please be informed that unplanned diversion at Changi Airport Terminal 2 for service 24, 27 and 53 has ceased.\n",
      "\n",
      "1\n",
      "[Bus service]Please be informed that Services 24, 27 and 53 will skip Changi Airport PTB2 bus stop as the bus stop is closed.\n",
      "\n",
      "1\n",
      "[Bus service]Please be informed that service 24, 27 and 53 will skip Changi Airport PTB2 bus stop due to vehicle emitting smoke\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Yet been stuck at novena for nearly twelve minute wtf\n",
      "\n",
      "1\n",
      "[Bus service]12/09, 6.18pm: NEL service has resumed. We are sorry for the inconvenience caused.\n",
      "\n",
      "2\n",
      "[Bus service]12/09 6.02pm: NEL service is delayed due to a train fault at Boon Keng NE9. Additional travel time of about 10 minutes may be expected.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore I waited 4mins for 1 train that was too crowded to board, and the train 9mins later is probably going to be the same\n",
      "\n",
      "1\n",
      "[Bus service]Services 4, 5, 9, 19, 29, 37, 59, 89 and 109 to skip bus stops in Changi and Loyang on 17 September. https://t.co/QO94lMfFk9\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Stop lying, the train I'm on still comes to halt between stations\n",
      "\n",
      "1\n",
      "[CCL] Update: Train services are running normally now.\n",
      "\n",
      "1\n",
      "[CCL Update]Train Service are progressively recovering. Free Regular Bus service available till 10.30am.\n",
      "\n",
      "1\n",
      "[CCL Update] Train Service are progressively recovering. Free Regular Bus service available till 10.30am.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore @LTAsg LTA also bloody useless\n",
      "\n",
      "1\n",
      "[CCL Update] please add 30mins additional travelling time from #PayaLebar to #BuonaVista due to train fault. Free Regular bus available.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore excuse me, i think you should also announce the delay along EWL too! Look at the numbers of tweets of pple complaining it!\n",
      "\n",
      "1\n",
      "[CCL Update] please add 30mins additional travelling time from #PayaLebar to #BuonaVista due to a train fault. Train Service still available\n",
      "\n",
      "2\n",
      "[CCL] UPDATE: Free regular bus services available between #PayaLebar and #BuonaVista.\n",
      "\n",
      "1\n",
      "[CCL] please add 15mins additional travelling time from #PayaLebar to #BuonaVista due to a train fault.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore No announcement for this uh? Dhoby Ghaut station and both platforms not moving https://t.co/rsTXSijz0G\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Right,1 hr 14mins, from Pasir Ris to JE. Thank you, i still havta suffer from JE to Joo Koon. Already missed my 8:55am bus.\n",
      "\n",
      "1\n",
      "@SMRT_Singapore any faulty along NSL? Train is moving very slow. I mean very very slow!!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore EWL is way snail slow. 7:35am boarded at Pasir Ris, now I just reach Queenstown. Seems like today break record again.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore train moving very very slow at NSL.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Train is slow, Pasir Ris to Aljunied took 30mins. It was only 20mins.\n",
      "\n",
      "1\n",
      "[BPLRT] CLEARED: Free bus and bridging bus services have ended. We apologise for the inconvenience caused.\n",
      "\n",
      "1\n",
      "[BPLRT] CLEARED: Normal service on the BPLRT has resumed.\n",
      "\n",
      "1\n",
      "@SMRT_Singapore MRT LRT everytime train fault on peak hours. Wake up your IDEA\n",
      "\n",
      "2\n",
      "@SMRT_Singapore 8mins waiting time at jurong east station. Towards Woodlands. During peak hr? Crazy\n",
      "\n",
      "1\n",
      "@SMRT_Singapore NSL train fault?! Train stop and moving slow.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Just waited almost 40 minutes for a bus 70. Saw 3x bus 7's go by. Please improve reliability\n",
      "\n",
      "1\n",
      "@SMRT_Singapore hello, what is happening from Jurong East to Joo Koon? Slow like snail and no announcement??!!\n",
      "\n",
      "2\n",
      "@SMRT_Singapore why is waiting time for train towards jurong is 6mins during peak hour??? Bodoh\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Train fault at Jurong East-Joo Koon stretch now. Expect delays.\n",
      "\n",
      "1\n",
      "[Bus service]Operating hrs of DTL, NEL and Sengkang/Punggol LRT and bus services 181, 222, 225G and 243G will be extended during F1 race days, 15 - 17 Sep.\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Your train stuck at Boon Lay is it? Why do we need to wait for 20mins???\n",
      "\n",
      "2\n",
      "@SMRT_Singapore Clear already but people still stuck from yishun to marina, what's the point smrt?\n"
     ]
    }
   ],
   "source": [
    "vectorsArr2 = readWrite.readFile('docVectors3.csv')\n",
    "oriRecords2 = readWrite.readOriFile('user_tweets3.txt')\n",
    "\n",
    "classResult = []\n",
    "predicted = model.predict_classes(vectorsArr2)\n",
    "predicted = np.reshape(predicted, (predicted.size,))\n",
    "\n",
    "print()\n",
    "print(predicted)\n",
    "\n",
    "for idx, score in enumerate(predicted):    \n",
    "    if(score >= 1): \n",
    "        classResult.append(oriRecords2[idx])       \n",
    "        print(predicted[idx])\n",
    "        print(oriRecords2[idx])        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
