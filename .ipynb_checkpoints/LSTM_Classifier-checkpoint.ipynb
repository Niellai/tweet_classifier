{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import import_notebook\n",
    "from readWrite import ReadWrite\n",
    "from vectorToDoc import VectorToDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 1125\n",
      "Read complete, total records: 1125\n",
      "x_train: 901, shape: (901, 20)\n",
      "y_train: 901, shape: (901,)\n",
      "x_test: 224, shape: (224, 20)\n",
      "y_test: 224, shape: (224,)\n",
      "encoding_train shape: (901, 3)\n",
      "encoding_test shape: (224, 3)\n"
     ]
    }
   ],
   "source": [
    "tweetFile = \"combineVectors.csv\"\n",
    "tweetClassFile = \"combineVectorsResult.txt\"\n",
    "\n",
    "readWrite = ReadWrite()\n",
    "xdata = readWrite.readFile(tweetFile)\n",
    "ydata = readWrite.readFileClassifier(tweetClassFile)\n",
    "\n",
    "x_train = xdata[:int(len(xdata) * 0.8) + 1]\n",
    "y_train = ydata[:int(len(ydata) * 0.8) + 1]\n",
    "x_test = xdata[int(len(xdata) * 0.8):-1]\n",
    "y_test = ydata[int(len(ydata) * 0.8):-1]\n",
    "\n",
    "print(\"x_train: {}, shape: {}\".format(len(x_train), x_train.shape))\n",
    "print(\"y_train: {}, shape: {}\".format(len(y_train), y_train.shape))\n",
    "print(\"x_test: {}, shape: {}\".format(len(x_test), x_test.shape))\n",
    "print(\"y_test: {}, shape: {}\".format(len(y_test), y_test.shape))\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ydata)\n",
    "encoded = encoder.transform(ydata)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "encoding = np_utils.to_categorical(encoded)\n",
    "\n",
    "encoding_train = encoding[:int(len(xdata) * 0.8) + 1]\n",
    "encoding_test = encoding[int(len(ydata) * 0.8):-1]\n",
    "print(\"encoding_train shape: {}\".format(encoding_train.shape))\n",
    "print(\"encoding_test shape: {}\".format(encoding_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 64)            128000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 194,303\n",
      "Trainable params: 194,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabSize = 2000\n",
    "outputDim = 64\n",
    "recordsSize = 20\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, outputDim, input_length=recordsSize))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, input_dim=(20,), activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 901 samples, validate on 224 samples\n",
      "Epoch 1/30\n",
      "901/901 [==============================] - 1s - loss: 0.5305 - acc: 0.7333 - val_loss: 0.2057 - val_acc: 0.9375\n",
      "Epoch 2/30\n",
      "901/901 [==============================] - 0s - loss: 0.4083 - acc: 0.8524 - val_loss: 0.2588 - val_acc: 0.9375\n",
      "Epoch 3/30\n",
      "901/901 [==============================] - 0s - loss: 0.3683 - acc: 0.8561 - val_loss: 0.2317 - val_acc: 0.9405\n",
      "Epoch 4/30\n",
      "901/901 [==============================] - 0s - loss: 0.3085 - acc: 0.8724 - val_loss: 0.1889 - val_acc: 0.9375\n",
      "Epoch 5/30\n",
      "901/901 [==============================] - 0s - loss: 0.2337 - acc: 0.9038 - val_loss: 0.1708 - val_acc: 0.9449\n",
      "Epoch 6/30\n",
      "901/901 [==============================] - 0s - loss: 0.1933 - acc: 0.9057 - val_loss: 0.1942 - val_acc: 0.9315\n",
      "Epoch 7/30\n",
      "901/901 [==============================] - 0s - loss: 0.1636 - acc: 0.9046 - val_loss: 0.2208 - val_acc: 0.9167\n",
      "Epoch 8/30\n",
      "901/901 [==============================] - 0s - loss: 0.1436 - acc: 0.9190 - val_loss: 0.2365 - val_acc: 0.9241\n",
      "Epoch 9/30\n",
      "901/901 [==============================] - 0s - loss: 0.1426 - acc: 0.9171 - val_loss: 0.2848 - val_acc: 0.9048\n",
      "Epoch 10/30\n",
      "901/901 [==============================] - 0s - loss: 0.1327 - acc: 0.9216 - val_loss: 0.2370 - val_acc: 0.9167\n",
      "Epoch 11/30\n",
      "901/901 [==============================] - 0s - loss: 0.1235 - acc: 0.9301 - val_loss: 0.2512 - val_acc: 0.9167\n",
      "Epoch 12/30\n",
      "901/901 [==============================] - 0s - loss: 0.1209 - acc: 0.9408 - val_loss: 0.2432 - val_acc: 0.8958\n",
      "Epoch 13/30\n",
      "901/901 [==============================] - 0s - loss: 0.1340 - acc: 0.9371 - val_loss: 0.2337 - val_acc: 0.9003\n",
      "Epoch 14/30\n",
      "901/901 [==============================] - 0s - loss: 0.1112 - acc: 0.9471 - val_loss: 0.2894 - val_acc: 0.8884\n",
      "Epoch 15/30\n",
      "901/901 [==============================] - 0s - loss: 0.1054 - acc: 0.9515 - val_loss: 0.3441 - val_acc: 0.8884\n",
      "Epoch 16/30\n",
      "901/901 [==============================] - 0s - loss: 0.0953 - acc: 0.9667 - val_loss: 0.3388 - val_acc: 0.8869\n",
      "Epoch 17/30\n",
      "901/901 [==============================] - 0s - loss: 0.1175 - acc: 0.9452 - val_loss: 0.3182 - val_acc: 0.8780\n",
      "Epoch 18/30\n",
      "901/901 [==============================] - 0s - loss: 0.0956 - acc: 0.9649 - val_loss: 0.3171 - val_acc: 0.8720\n",
      "Epoch 19/30\n",
      "901/901 [==============================] - 0s - loss: 0.0938 - acc: 0.9667 - val_loss: 0.3474 - val_acc: 0.8616\n",
      "Epoch 20/30\n",
      "901/901 [==============================] - 0s - loss: 0.0888 - acc: 0.9674 - val_loss: 0.3279 - val_acc: 0.8824\n",
      "Epoch 21/30\n",
      "901/901 [==============================] - 0s - loss: 0.0673 - acc: 0.9763 - val_loss: 0.4151 - val_acc: 0.8557\n",
      "Epoch 22/30\n",
      "901/901 [==============================] - 0s - loss: 0.0616 - acc: 0.9804 - val_loss: 0.3886 - val_acc: 0.8795\n",
      "Epoch 23/30\n",
      "901/901 [==============================] - 0s - loss: 0.0588 - acc: 0.9826 - val_loss: 0.4235 - val_acc: 0.8661\n",
      "Epoch 24/30\n",
      "901/901 [==============================] - 0s - loss: 0.0594 - acc: 0.9834 - val_loss: 0.3821 - val_acc: 0.8765\n",
      "Epoch 25/30\n",
      "901/901 [==============================] - 0s - loss: 0.0540 - acc: 0.9856 - val_loss: 0.4024 - val_acc: 0.8690\n",
      "Epoch 26/30\n",
      "901/901 [==============================] - 0s - loss: 0.0584 - acc: 0.9819 - val_loss: 0.3929 - val_acc: 0.8795\n",
      "Epoch 27/30\n",
      "901/901 [==============================] - 0s - loss: 0.0447 - acc: 0.9859 - val_loss: 0.4706 - val_acc: 0.8616\n",
      "Epoch 28/30\n",
      "901/901 [==============================] - 0s - loss: 0.0409 - acc: 0.9878 - val_loss: 0.5351 - val_acc: 0.8452\n",
      "Epoch 29/30\n",
      "901/901 [==============================] - 0s - loss: 0.0478 - acc: 0.9848 - val_loss: 0.4968 - val_acc: 0.8363\n",
      "Epoch 30/30\n",
      "901/901 [==============================] - 0s - loss: 0.0483 - acc: 0.9871 - val_loss: 0.3684 - val_acc: 0.8810\n",
      "Accuracy: 88.10%\n"
     ]
    }
   ],
   "source": [
    "batch_size = outputDim\n",
    "epochs = 30\n",
    "\n",
    "model.fit(x_train, encoding_train, validation_data=(x_test, encoding_test), epochs=epochs, batch_size=outputDim)\n",
    "scores = model.evaluate(x_test, encoding_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete, total records: 510\n",
      "(510,)\n",
      "229 : 21\n"
     ]
    }
   ],
   "source": [
    "vectorsArr2 = readWrite.readFile('docVectors3.csv')\n",
    "oriRecords2 = readWrite.readOriFile('user_tweets3.txt')\n",
    "\n",
    "print(vectorsArr2.shape)\n",
    "\n",
    "for idx, item in enumerate(vectorsArr2):\n",
    "    if(len(item) > 20):\n",
    "        print(\"{} : {}\".format(idx, item))\n",
    "\n",
    "# classResult = []\n",
    "# predicted = model.predict_classes(vectorsArr2)\n",
    "# predicted = np.reshape(predicted, (predicted.size,))\n",
    "\n",
    "# print()\n",
    "# print(predicted.shape)\n",
    "\n",
    "# for idx, score in enumerate(predicted):    \n",
    "#     if(score >= 1): \n",
    "#         classResult.append(oriRecords2[idx])       \n",
    "#         print(predicted[idx])\n",
    "#         print(oriRecords2[idx])        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
