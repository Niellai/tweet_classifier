{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import load_model\n",
    "\n",
    "import import_notebook\n",
    "from readWrite import ReadWrite\n",
    "from vectorToDoc import VectorToDoc\n",
    "from docToVector import DocToVector\n",
    "from dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line size more than 20, trim to: ['2356', ' 1257', ' 1689', ' 1391', ' 2330', ' 791', ' 80', ' 1060', ' 2002', ' 1884', ' 1060', ' 300', ' 2330', ' 1135', ' 1799', ' 2073', ' 1165', ' 2253', ' 185', ' 1207']\n",
      "line size more than 20, trim to: ['2356', ' 1257', ' 1239', ' 500', ' 851', ' 1568', ' 1932', ' 851', ' 1239', ' 2153', ' 138', ' 1239', ' 455', ' 1008', ' 1044', ' 21', ' 1243', ' 1302', ' 851', ' 1503']\n",
      "Read complete, total records: 1814\n",
      "Read complete, total records: 1814\n",
      "x_train: 1452, shape: (1452, 20)\n",
      "y_train: 1452, shape: (1452,)\n",
      "x_test: 362, shape: (362, 20)\n",
      "y_test: 362, shape: (362,)\n",
      "encoding_train shape: (1452, 3)\n",
      "encoding_test shape: (362, 3)\n"
     ]
    }
   ],
   "source": [
    "tweetFile = \"combineVectors.csv\"\n",
    "tweetClassFile = \"combineVectorsResult.txt\"\n",
    "\n",
    "readWrite = ReadWrite()\n",
    "xdata = readWrite.readFile(tweetFile)\n",
    "ydata = readWrite.readFileClassifier(tweetClassFile)\n",
    "\n",
    "x_train = xdata[:int(len(xdata) * 0.8) + 1]\n",
    "y_train = ydata[:int(len(ydata) * 0.8) + 1]\n",
    "x_test = xdata[int(len(xdata) * 0.8):-1]\n",
    "y_test = ydata[int(len(ydata) * 0.8):-1]\n",
    "\n",
    "print(\"x_train: {}, shape: {}\".format(len(x_train), x_train.shape))\n",
    "print(\"y_train: {}, shape: {}\".format(len(y_train), y_train.shape))\n",
    "print(\"x_test: {}, shape: {}\".format(len(x_test), x_test.shape))\n",
    "print(\"y_test: {}, shape: {}\".format(len(y_test), y_test.shape))\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ydata)\n",
    "encoded = encoder.transform(ydata)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "encoding = np_utils.to_categorical(encoded)\n",
    "\n",
    "encoding_train = encoding[:int(len(xdata) * 0.8) + 1]\n",
    "encoding_test = encoding[int(len(ydata) * 0.8):-1]\n",
    "print(\"encoding_train shape: {}\".format(encoding_train.shape))\n",
    "print(\"encoding_test shape: {}\".format(encoding_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 64)            192000    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 217,027\n",
      "Trainable params: 217,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabSize = 3000\n",
    "outputDim = 64\n",
    "recordsSize = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, outputDim, input_length=recordsSize))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1452 samples, validate on 362 samples\n",
      "Epoch 1/30\n",
      "1452/1452 [==============================] - 7s - loss: 0.4791 - acc: 0.7842 - val_loss: 0.4609 - val_acc: 0.8002\n",
      "Epoch 2/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.3430 - acc: 0.8717 - val_loss: 0.4000 - val_acc: 0.8177\n",
      "Epoch 3/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.2683 - acc: 0.8942 - val_loss: 0.3469 - val_acc: 0.8517\n",
      "Epoch 4/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.2055 - acc: 0.9148 - val_loss: 0.4364 - val_acc: 0.8527\n",
      "Epoch 5/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.1746 - acc: 0.9233 - val_loss: 0.4300 - val_acc: 0.8610\n",
      "Epoch 6/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.1488 - acc: 0.9401 - val_loss: 0.4283 - val_acc: 0.8711\n",
      "Epoch 7/30\n",
      "1452/1452 [==============================] - 5s - loss: 0.1258 - acc: 0.9440 - val_loss: 0.4986 - val_acc: 0.8692\n",
      "Epoch 8/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.1115 - acc: 0.9532 - val_loss: 0.7921 - val_acc: 0.8591\n",
      "Epoch 9/30\n",
      "1452/1452 [==============================] - 5s - loss: 0.0950 - acc: 0.9628 - val_loss: 0.7826 - val_acc: 0.8637\n",
      "Epoch 10/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.1025 - acc: 0.9598 - val_loss: 0.6454 - val_acc: 0.8628\n",
      "Epoch 11/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0726 - acc: 0.9708 - val_loss: 0.7754 - val_acc: 0.8582\n",
      "Epoch 12/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0593 - acc: 0.9791 - val_loss: 0.6780 - val_acc: 0.8481\n",
      "Epoch 13/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0489 - acc: 0.9862 - val_loss: 0.8543 - val_acc: 0.8564\n",
      "Epoch 14/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0402 - acc: 0.9844 - val_loss: 1.0265 - val_acc: 0.8564\n",
      "Epoch 15/30\n",
      "1452/1452 [==============================] - 5s - loss: 0.0407 - acc: 0.9848 - val_loss: 0.9976 - val_acc: 0.8481\n",
      "Epoch 16/30\n",
      "1452/1452 [==============================] - 3s - loss: 0.0336 - acc: 0.9906 - val_loss: 0.9168 - val_acc: 0.8444\n",
      "Epoch 17/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0354 - acc: 0.9892 - val_loss: 1.0062 - val_acc: 0.8573\n",
      "Epoch 18/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0274 - acc: 0.9920 - val_loss: 1.0057 - val_acc: 0.8462\n",
      "Epoch 19/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0308 - acc: 0.9910 - val_loss: 1.1221 - val_acc: 0.8637\n",
      "Epoch 20/30\n",
      "1452/1452 [==============================] - 5s - loss: 0.0228 - acc: 0.9949 - val_loss: 1.0846 - val_acc: 0.8582\n",
      "Epoch 21/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.9904 - val_acc: 0.8573\n",
      "Epoch 22/30\n",
      "1452/1452 [==============================] - 3s - loss: 0.0216 - acc: 0.9943 - val_loss: 1.0412 - val_acc: 0.8656\n",
      "Epoch 23/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0191 - acc: 0.9945 - val_loss: 1.1044 - val_acc: 0.8600\n",
      "Epoch 24/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0174 - acc: 0.9959 - val_loss: 1.1711 - val_acc: 0.8610\n",
      "Epoch 25/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0171 - acc: 0.9949 - val_loss: 1.2138 - val_acc: 0.8545\n",
      "Epoch 26/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0181 - acc: 0.9949 - val_loss: 1.0165 - val_acc: 0.8462\n",
      "Epoch 27/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0158 - acc: 0.9961 - val_loss: 1.0988 - val_acc: 0.8536\n",
      "Epoch 28/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0132 - acc: 0.9966 - val_loss: 1.2778 - val_acc: 0.8517\n",
      "Epoch 29/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0081 - acc: 0.9982 - val_loss: 1.2356 - val_acc: 0.8536\n",
      "Epoch 30/30\n",
      "1452/1452 [==============================] - 4s - loss: 0.0149 - acc: 0.9959 - val_loss: 1.3053 - val_acc: 0.8462\n",
      "Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# while(True):        \n",
    "#     model.fit(x_train, encoding_train, validation_data=(x_test, encoding_test), epochs=epochs, batch_size=outputDim, verbose=2)\n",
    "#     scores = model.evaluate(x_test, encoding_test, verbose=0)    \n",
    "#     print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "#     if(scores[1] > 0.85):\n",
    "#         break\n",
    "#     else:\n",
    "#         clear_output()\n",
    "\n",
    "model.fit(x_train, encoding_train, epochs=epochs, \n",
    "          batch_size=batch_size, validation_data=[x_test, encoding_test])\n",
    "scores = model.evaluate(x_test, encoding_test, verbose=0)    \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Saving model or load model\n",
    "'''\n",
    "model.save('model/bidir_model_Laptop.h5')\n",
    "# model = load_model('model/bidir_model_Laptop.h5')\n",
    "\n",
    "scores = model.evaluate(x_test, encoding_test, verbose=0)    \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary count: 2307\n",
      "Dictionary count: 2305\n",
      "[['ccl', 'updat', 'pleas', 'add', 'min', 'addit', 'travel', 'time', 'payalebar', 'buonavista', 'due', 'train', 'fault', 'free', 'regular', 'bu', 'avail']]\n",
      "Converting records to vectors...\n",
      "Max length of record: 20\n",
      "IsPadding enable: True\n",
      "[[1795 1052  717  792 2048 1696 2001  486 1204 1341 1027 1069 2140  206\n",
      "  1385 1521  767    0    0    0]]\n",
      "[['ccl', 'updat', 'pleas', 'add', 'min', 'addit', 'travel', 'time', 'payalebar', 'buonavista', 'due', 'train', 'fault', 'free', 'regular', 'bu', 'avail', 'NONE', 'NONE', 'NONE']]\n",
      "1/1 [==============================] - 0s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Classify sentence\n",
    "0-unknown, 1-update, 2-delay\n",
    "'''\n",
    "def classify_sentence(sentence, debug=False):\n",
    "    dic = Dictionary()\n",
    "    vectorToDoc = VectorToDoc()\n",
    "    docToVector = DocToVector()\n",
    "    senArr = dic.readSentence(sentence, True)\n",
    "    if(debug):\n",
    "        print(senArr)\n",
    "\n",
    "    vector = docToVector.convertVector(senArr, True)\n",
    "    sen = vectorToDoc.convertDoc(vector)\n",
    "    vector = np.array(vector)\n",
    "    if(debug):\n",
    "        print(vector)\n",
    "        print(sen)\n",
    "\n",
    "    predicted = model.predict_classes(vector)\n",
    "    print(predicted[0])\n",
    "    \n",
    "classify_sentence(\"[CCL Update] please add 30mins additional travelling time from #PayaLebar to #BuonaVista due to train fault. Free Regular bus available.\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary count: 2305\n",
      "Converting records to vectors...\n",
      "Max length of record: 20\n",
      "IsPadding enable: True\n",
      "vector records shape: (44, 20)\n",
      "32/44 [====================>.........] - ETA: 0s\n",
      "(44,)\n",
      "2\n",
      "@SMRT_Singapore Ooo.oh,,th mmm n n.I'll\n",
      "\n",
      "1\n",
      "@SMRT_Singapore hello, what is happening from Jurong East to Joo Koon? Slow like snail and no announcement??!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "0-unknown, 1-update, 2-delay\n",
    "'''\n",
    "dic = Dictionary()\n",
    "docToVector = DocToVector()\n",
    "\n",
    "testArr = dic.readFile(\"user_tweets4.txt\", True)\n",
    "vectorsArr2 = docToVector.convertVector(testArr, True)\n",
    "vectorsArr2 = np.array(vectorsArr2)\n",
    "oriRecords2 = readWrite.readOriFile('user_tweets4.txt')\n",
    "\n",
    "# vectorsArr2 = readWrite.readFile('docVectors3.csv')\n",
    "# oriRecords2 = readWrite.readOriFile('user_tweets3.txt')\n",
    "\n",
    "print(\"vector records shape: {}\".format(vectorsArr2.shape))\n",
    "\n",
    "classResult = []\n",
    "predicted = model.predict_classes(vectorsArr2)\n",
    "predicted = np.reshape(predicted, (predicted.size,))\n",
    "\n",
    "print()\n",
    "print(predicted.shape)\n",
    "\n",
    "for idx, score in enumerate(predicted):    \n",
    "    if(score > 0): \n",
    "        classResult.append(oriRecords2[idx])       \n",
    "        print(predicted[idx])\n",
    "        print(oriRecords2[idx])        \n",
    "\n",
    "# readWrite.writeFile('docVectors3Result.txt', predicted)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
